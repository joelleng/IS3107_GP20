{
  "components": {
    "comp-data-processing-direct": {
      "executorLabel": "exec-data-processing-direct"
    },
    "comp-evaluate-model-direct": {
      "executorLabel": "exec-evaluate-model-direct",
      "inputDefinitions": {
        "artifacts": {
          "model_path": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-model-direct": {
      "executorLabel": "exec-train-model-direct",
      "outputDefinitions": {
        "artifacts": {
          "model_path": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "defaultPipelineRoot": "gs://is3107-car-data/pipeline-artifacts",
  "deploymentSpec": {
    "executors": {
      "exec-data-processing-direct": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "data_processing_direct"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'google-cloud-bigquery' 'scikit-learn' 'db-dtypes' 'sentence-transformers' 'pickle5' 'google-cloud-storage' 'google-cloud-bigquery-storage' 'pandas-gbq' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef data_processing_direct():\n    import os, re\n    import pandas as pd\n    import numpy as np\n    from joblib import dump\n    import pickle5 as pickle\n    from sklearn.ensemble import RandomForestRegressor\n    from google.cloud import bigquery, storage\n    from sklearn.preprocessing import StandardScaler\n    from sentence_transformers import SentenceTransformer\n    from sklearn.decomposition import PCA\n\n    GCP_PROJECT_ID = 'is3107-453814'\n    BQ_DATASET_ID = 'car_dataset'\n    BQ_TABLE_ID = 'used_car'\n    BUCKET_NAME = 'is3107-bucket'\n    BUCKET_FOLDER = 'mlops'\n\n    client = bigquery.Client(project=GCP_PROJECT_ID)\n    table_key = f\"{BQ_DATASET_ID}.{BQ_TABLE_ID}\"\n    query = f\"SELECT * FROM {table_key} WHERE used_car_id IS NOT NULL AND listing_url IS NOT NULL AND car_model IS NOT NULL AND brand IS NOT NULL AND color IS NOT NULL AND fuel_type IS NOT NULL AND price IS NOT NULL AND depreciation_per_year IS NOT NULL AND registration_date IS NOT NULL AND coe_left IS NOT NULL AND mileage IS NOT NULL AND manufactured_year IS NOT NULL AND road_tax_per_year IS NOT NULL AND transmission IS NOT NULL AND dereg_value IS NOT NULL AND omv IS NOT NULL AND coe_value IS NOT NULL AND arf IS NOT NULL AND engine_capacity_cc IS NOT NULL AND power IS NOT NULL AND curb_weight IS NOT NULL AND no_of_owners IS NOT NULL AND vehicle_type IS NOT NULL AND scraped_datetime IS NOT NULL AND posted_datetime IS NOT NULL AND updated_datetime IS NOT NULL AND active IS NOT NULL\"\n\n    df = client.query(query).to_dataframe()\n\n    def initial_data_cleaning(df):\n        \"\"\"Performs initial cleaning on used car DataFrame.\n\n        Args:\n            df (pd.DataFrame): Raw used car data\n\n        Returns:\n            pd.DataFrame: Cleaned DataFrame ready for further processing\n        \"\"\"\n        df = df.copy()\n\n        # Data Cleaning 1: Remove duplicates\n        df.drop_duplicates(inplace=True)\n\n        # Data Cleaning 2: Drop where active==False -> this is when in the future we have future training where we want to set certain dataset/entries to be False\n        df = df[df['active'].astype(bool)]\n\n        # Data Cleaning 2: listing_url, active column as it should not be a feature in ML except used_car_id as it is needed for reference\n        df.drop(columns=['listing_url', 'active'], inplace=True)\n\n        # Data Cleaning 3: Convert scraped_datetime, posted_datetime, updated_datetime to datetime\n        datetime_cols = ['scraped_datetime', 'posted_datetime', 'updated_datetime']\n        df[datetime_cols] = df[datetime_cols].apply(pd.to_datetime)\n\n        return df\n\n    def feature_engineer_car_age(df):\n        \"\"\"Adds a new column 'car_age' to the DataFrame.\n\n        Args:\n            df (pd.DataFrame): DataFrame containing car data\n\n        Returns:\n            pd.DataFrame: DataFrame with 'car_age' column added\n        \"\"\"\n        current_year = pd.to_datetime('now').year\n        df = df.copy()\n        df['car_age'] = current_year - df['manufactured_year']\n\n        df.drop(columns=['manufactured_year'], inplace=True)\n\n        return df\n\n    def feature_engineer_temporal_features(df):\n        df = df.copy()\n\n        # 1. Days on market\n        df['days_on_market'] = (df['scraped_datetime'] - df['posted_datetime']).dt.days\n\n        # Drop original datetime columns (optional)\n        df.drop(columns=['posted_datetime', 'scraped_datetime', 'updated_datetime', 'registration_date'], inplace=True)\n\n        return df\n\n    def feature_engineer_clean_model_name(df):\n        # Standardize to lowercase, remove punctuation/extra spaces\n        df = df.copy()\n        df['car_model'] = df['car_model'].apply(lambda x:  re.sub(r'[^\\w\\s]', '', str(x).lower().strip()))\n        return df\n\n    def feature_engineer_car_model_embedding(df):\n        df = df.copy()\n        # Load pretrained model\n        model = SentenceTransformer('all-MiniLM-L6-v2')\n        df['car_model_embedding'] = list(model.encode(df['car_model'].astype(str)))\n        return df\n\n    def save_to_gcs(bucket_name, object_name, model):\n        \"\"\"Saves model to GCS bucket\"\"\"\n        storage_client = storage.Client()\n        bucket = storage_client.bucket(bucket_name)\n        blob = bucket.blob(f'{BUCKET_FOLDER}/{object_name}')\n\n        with blob.open('wb') as f:\n            pickle.dump(model, f)\n\n    def feature_engineer_dummys(df):\n        \"\"\"Creates dummy variables for categorical features.\n\n        Args:\n            df (pd.DataFrame): DataFrame containing car data\n\n        Returns:\n            pd.DataFrame: DataFrame with dummy variables added\n        \"\"\"\n        df = df.copy()\n        categorical_cols = ['brand', 'color', 'fuel_type', 'transmission', 'vehicle_type']\n        # categorical_cols = ['brand', 'car_model', 'color', 'fuel_type', 'transmission', 'vehicle_type']\n\n        for col in categorical_cols:\n            if col in df.columns:\n                df[col] = (\n                    df[col]\n                    .astype(str)\n                    .str.strip()\n                    .str.lower()\n                    .str.replace(r'[^\\w\\s]', '', regex=True)  # Removes punctuation\n                )\n\n        # Create dummies for categorical features\n        df = pd.get_dummies(\n            df, \n            columns=categorical_cols,\n            prefix_sep='_',\n            drop_first=True  # Reduces multicollinearity by dropping first category\n        )\n\n        return df\n\n    df_cleaned = initial_data_cleaning(df)\n    df_with_car_age = feature_engineer_car_age(df_cleaned)\n    df_temporal = feature_engineer_temporal_features(df_with_car_age)\n    df_cleaned_model = feature_engineer_clean_model_name(df_temporal)\n    df_embedded = feature_engineer_car_model_embedding(df_cleaned_model)\n    final_df = df_embedded.copy()\n    final_df.drop(columns=['car_model'], inplace=True)\n    embedding_df = pd.DataFrame(final_df[\"car_model_embedding\"].tolist()).add_prefix(\"embedding_\")\n    final_df.drop(columns=[\"car_model_embedding\"], inplace=True)\n    final_df = pd.concat([final_df, embedding_df], axis=1)\n    final_df.rename(columns={\"used_car_id\": \"id\"}, inplace=True)\n\n    ### Upload this dataset to the data-cleaned_table if id not in the table\n    table_key = f\"{BQ_DATASET_ID}.data-cleaned_table\"\n\n    final_df.to_gbq(\n        destination_table=table_key,\n        project_id=GCP_PROJECT_ID,\n        if_exists='replace'  # This will overwrite the entire table\n    )\n\n    ### Continue with other feature engineering steps\n    numeric_cols = ['depreciation_per_year', 'coe_left', 'mileage', 'dereg_value', \n                    'omv', 'coe_value', 'arf', 'car_age', 'days_on_market',\n                    'road_tax_per_year', 'engine_capacity_cc', 'power', 'curb_weight']\n    pca_cols = [col for col in numeric_cols if col != 'no_of_owners' and not col.startswith('embedding_')] # Number of owners is a discrete, categorical feature\n    pca_df = final_df.copy()[pca_cols]\n\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(pca_df[pca_cols])\n\n    save_to_gcs(BUCKET_NAME, 'latest_scaler.pkl', scaler)\n\n    pca_7 = PCA(n_components=7)\n    pca_7_components = pca_7.fit_transform(scaled_data)\n\n    ### Save PCA components to Bucket -- doesnt matter the file name as it will be overwritten -> we can hence call from a consistent file_name in the prediction pipeline\n    save_to_gcs(BUCKET_NAME, 'latest_pca.pkl', pca_7)\n\n    pca_7_df = pd.DataFrame(pca_7_components, columns=[f'PC{i+1}' for i in range(7)], index=final_df.index)\n\n    non_pca_cols = final_df.drop(columns=pca_cols).copy()  # These include 'no_of_owners' and any other non-numeric cols\n\n\n    combined_df = pd.concat([pca_7_df, non_pca_cols], axis=1)\n    combined_df.head()\n\n    df_dummy = feature_engineer_dummys(combined_df)\n\n    ### Save the final feature engineered dataset to BigQuery\n    table_key = f\"{BQ_DATASET_ID}.data-feature_engineered\"\n    df_dummy.to_gbq(\n        destination_table=table_key,\n        project_id=GCP_PROJECT_ID,\n        if_exists='replace'  # This will overwrite the entire table\n    )\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-evaluate-model-direct": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "evaluate_model_direct"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'google-cloud-bigquery' 'scikit-learn' 'joblib' 'db-dtypes' 'google-cloud-storage' 'xgboost' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef evaluate_model_direct(\n    model_path: Input[Model],\n    metrics: Output[Metrics]\n):\n    \"\"\"Samples a small subset from the feature table, computes RMSE and R\u00b2.\"\"\"\n    import pandas as pd\n    from joblib import load\n    import math\n    from sklearn.metrics import mean_squared_error, r2_score\n    from google.cloud import bigquery, storage\n    import json\n\n    project = 'is3107-453814'\n    dataset = 'car_dataset'\n    FEATURE_TABLE = f\"{project}.{dataset}.data-feature_engineered\"\n\n    client = bigquery.Client(project=project)\n    # pull only a small sample for testing\n    df = client.query(\n        f\"SELECT * FROM `{FEATURE_TABLE}` LIMIT 1000\"\n    ).to_dataframe()\n\n    df.drop(columns=[\"id\"], inplace=True)\n    df = df.astype({col: int for col in df.select_dtypes(include='bool').columns})\n\n    X_test = df.drop(columns=['price'])\n    y_test = df['price']\n\n    model = load(model_path.path + \".joblib\")\n    y_pred = model.predict(X_test)\n\n    rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n\n    with open(metrics.path, 'w') as f:\n        json.dump({\"rmse\": rmse, \"r2_score\": r2}, f)\n\n    # upload the metrics JSON to the specific bucket\n    BUCKET_NAME   = \"is3107-bucket\"\n    BUCKET_FOLDER = \"mlops\"\n    gcs_client = storage.Client()\n    bucket     = gcs_client.bucket(BUCKET_NAME)\n    blob_name  = f\"{BUCKET_FOLDER}/latest_metrics.json\"\n    bucket.blob(blob_name).upload_from_filename(metrics.path)\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-train-model-direct": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_model_direct"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'google-cloud-bigquery' 'scikit-learn' 'joblib' 'db-dtypes' 'google-cloud-storage' 'xgboost' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_model_direct(\n    model_path: Output[Model]\n):\n    \"\"\"Loads feature-engineered table from BigQuery, trains with XGBoost, uploads model.\"\"\"\n    import pandas as pd\n    from joblib import dump\n    from xgboost import XGBRegressor\n    from google.cloud import bigquery, storage\n\n\n    project = 'is3107-453814'\n    dataset = 'car_dataset'\n    FEATURE_TABLE = f\"{project}.{dataset}.data-feature_engineered\"\n\n    client = bigquery.Client(project=project)\n    df = client.query(f\"SELECT * FROM `{FEATURE_TABLE}`\").to_dataframe()\n    df.drop(columns=[\"id\"], inplace=True)\n    df = df.astype({col: int for col in df.select_dtypes(include='bool').columns})\n\n\n    X = df.drop(columns=['price'])\n    y = df['price']\n\n\n    model = XGBRegressor(\n        objective='reg:squarederror',\n        subsample=0.6,\n        reg_lambda=2,\n        reg_alpha=1,\n        n_estimators=300,\n        max_depth=7,\n        learning_rate=0.1,\n        colsample_bytree=0.8,\n        random_state=42,\n        n_jobs=-1\n    )\n    model.fit(X, y)\n\n\n    # 1) dump locally\n    dump(model, model_path.path + \".joblib\")\n\n    # 2) upload to GCS at specific bucket\n    BUCKET_NAME   = \"is3107-bucket\"\n    BUCKET_FOLDER = \"mlops\"\n    gcs_client = storage.Client()\n    bucket     = gcs_client.bucket(BUCKET_NAME)\n    blob_name  = f\"{BUCKET_FOLDER}/latest_model.joblib\"\n    bucket.blob(blob_name).upload_from_filename(model_path.path + \".joblib\")\n\n"
          ],
          "image": "python:3.9"
        }
      }
    }
  },
  "pipelineInfo": {
    "name": "car-price-retrain"
  },
  "root": {
    "dag": {
      "tasks": {
        "data-processing-direct": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-data-processing-direct"
          },
          "taskInfo": {
            "name": "data-processing-direct"
          }
        },
        "evaluate-model-direct": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-evaluate-model-direct"
          },
          "dependentTasks": [
            "train-model-direct"
          ],
          "inputs": {
            "artifacts": {
              "model_path": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model_path",
                  "producerTask": "train-model-direct"
                }
              }
            }
          },
          "taskInfo": {
            "name": "evaluate-model-direct"
          }
        },
        "train-model-direct": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-model-direct"
          },
          "dependentTasks": [
            "data-processing-direct"
          ],
          "taskInfo": {
            "name": "train-model-direct"
          }
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.12.1"
}